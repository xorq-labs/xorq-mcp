{
  "current_library_version": "0.3.7",
  "metadata_version": "0.0.0",
  "git_state": {
    "commit": "f51ea3e78456a2e5e39655f5051d1c8e57f262b1",
    "diff": "diff --git a/examples/README.md b/examples/README.md\nindex cf2f4dfb..04094d66 100644\n--- a/examples/README.md\n+++ b/examples/README.md\n@@ -1,18 +1,56 @@\n How to run the examples\n =======================\n \n-1. `just download-data` to download the testing data\n-2. `just up postgres` to launch the postgres instance\n-3. `uv sync --extra examples --extra postgres` to install the proper dependencies\n-3. `pip install .[examples] .[postgres]` to install proper dependencies with pip\n-4. `brew install libomp`\n+## Setup\n \n-Then:\n+From the repo root:\n \n ```bash\n+# macOS only\n+brew install cmake libomp\n+\n+# Install dependencies (from repo root)\n+uv sync --extra examples --extra postgres\n+\n+# Activate the venv\n+source .venv/bin/activate\n+```\n+\n+## Running examples\n+\n+Most examples work out of the box:\n+\n+```bash\n+cd examples\n+python simple_example.py\n python local_cache.py\n ```\n \n+### Examples that require local PostgreSQL\n+\n+Some examples write to PostgreSQL and need a local instance:\n+\n+```bash\n+# Start postgres (from repo root)\n+just up postgres\n+```\n+\n+The default connection credentials match the docker compose config, so no environment variables are needed.\n+To override, set `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_HOST`, `POSTGRES_PORT`, `POSTGRES_DATABASE`.\n+\n+Scripts requiring local postgres: `deferred_read_csv.py`, `multi_engine.py`, `remote_caching.py`\n+\n+### Examples that require API keys\n+\n+| Script | Environment variable |\n+|--------|---------------------|\n+| `weather_flight.py` | `OPENWEATHER_API_KEY` |\n+| `flight_udtf_llm_example.py` | `OPENAI_API_KEY` |\n+\n+### CLI-style examples\n+\n+`duckdb_flight_example.py` requires a subcommand: `python duckdb_flight_example.py serve`\n+\n ## Examples\n \n ### Getting Started\ndiff --git a/python/xorq/env_templates/.env.postgres.template b/python/xorq/env_templates/.env.postgres.template\nindex 70ef984d..4fb5f89a 100644\n--- a/python/xorq/env_templates/.env.postgres.template\n+++ b/python/xorq/env_templates/.env.postgres.template\n@@ -1,5 +1,5 @@\n-POSTGRES_USER=\n-POSTGRES_PASSWORD=\n-POSTGRES_HOST=\n-POSTGRES_PORT=\n-POSTGRES_DATABASE=\n+POSTGRES_USER=postgres\n+POSTGRES_PASSWORD=postgres\n+POSTGRES_HOST=localhost\n+POSTGRES_PORT=5432\n+POSTGRES_DATABASE=ibis_testing",
    "diff_cached": "diff --git a/examples/complex_cached_expr.py b/examples/complex_cached_expr.py\nindex 6f7d508c..3432a10f 100644\n--- a/examples/complex_cached_expr.py\n+++ b/examples/complex_cached_expr.py\n@@ -13,7 +13,6 @@ from xorq.caching import (\n     SourceCache,\n )\n from xorq.common.utils.defer_utils import deferred_read_parquet\n-from xorq.common.utils.import_utils import import_python\n from xorq.common.utils.toolz_utils import curry\n from xorq.expr.ml import (\n     deferred_fit_predict,\n@@ -33,12 +32,8 @@ expected_transform_command = \"execute-unbound-expr-d785a558027791af18dac689ed381\n expected_predict_command = \"execute-unbound-expr-2f54734d557f2914929e8f0fc8784c42\"\n \n \n-do_hackernews_fetcher_udxf = import_python(\n-    xo.options.pins.get_path(\"hackernews_lib\", version=\"20250604T223424Z-2e578\")\n-).do_hackernews_fetcher_udxf\n-do_hackernews_sentiment_udxf = import_python(\n-    xo.options.pins.get_path(\"openai_lib\", version=\"20250604T223419Z-0ce44\")\n-).do_hackernews_sentiment_udxf\n+from libs.hackernews_lib import do_hackernews_fetcher_udxf\n+from libs.openai_lib import do_hackernews_sentiment_udxf\n \n \n @curry\ndiff --git a/examples/flight_exchange_example.py b/examples/flight_exchange_example.py\nindex 19c16da3..c795b654 100644\n--- a/examples/flight_exchange_example.py\n+++ b/examples/flight_exchange_example.py\n@@ -6,7 +6,6 @@ import pyarrow as pa\n \n import xorq.api as xo\n import xorq.expr.datatypes as dt\n-from xorq.common.utils import classproperty\n from xorq.common.utils.rbr_utils import (\n     instrument_reader,\n     streaming_split_exchange,\n@@ -30,8 +29,8 @@ def train_batch_df(df):\n \n \n class IterativeSplitTrainExchanger(AbstractExchanger):\n-    @classproperty\n-    def exchange_f(cls):\n+    @property\n+    def exchange_f(self):\n         def train_batch(split_reader):\n             df = split_reader.read_pandas()\n             (split, *rest) = df[SPLIT_KEY].unique()\n@@ -47,19 +46,19 @@ class IterativeSplitTrainExchanger(AbstractExchanger):\n \n         return functools.partial(streaming_split_exchange, SPLIT_KEY, train_batch)\n \n-    @classproperty\n-    def schema_in_required(cls):\n+    @property\n+    def schema_in_required(self):\n         return None\n \n-    @classproperty\n-    def schema_in_condition(cls):\n+    @property\n+    def schema_in_condition(self):\n         def condition(schema_in):\n             return any(name == SPLIT_KEY for name in schema_in)\n \n         return condition\n \n-    @classproperty\n-    def calc_schema_out(cls):\n+    @property\n+    def calc_schema_out(self):\n         def f(schema_in):\n             return xo.schema(\n                 {\n@@ -70,14 +69,24 @@ class IterativeSplitTrainExchanger(AbstractExchanger):\n \n         return f\n \n-    @classproperty\n-    def description(cls):\n+    @property\n+    def description(self):\n         return \"iteratively train model on data ordered by `split`\"\n \n-    @classproperty\n-    def command(cls):\n+    @property\n+    def command(self):\n         return \"iterative-split-train\"\n \n+    @property\n+    def query_result(self):\n+        return {\n+            \"schema-in-required\": self.schema_in_required,\n+            \"schema-in-condition\": self.schema_in_condition,\n+            \"calc-schema-out\": self.calc_schema_out,\n+            \"description\": self.description,\n+            \"command\": self.command,\n+        }\n+\n \n def train_test_split_union(expr, name=SPLIT_KEY, *args, **kwargs):\n     splits = xo.expr.ml.train_test_splits(expr, *args, **kwargs)\n@@ -100,15 +109,16 @@ expr = train_test_split_union(\n \n if __name__ in (\"__pytest_main__\", \"__main__\"):\n     rbr_in = instrument_reader(xo.to_pyarrow_batches(expr), prefix=\"input ::\")\n+    exchanger = IterativeSplitTrainExchanger()\n     with FlightServer() as server:\n         client = server.client\n         client.do_action(\n             AddExchangeAction.name,\n-            IterativeSplitTrainExchanger,\n+            exchanger,\n             options=client._options,\n         )\n         (fut, rbr_out) = client.do_exchange_batches(\n-            IterativeSplitTrainExchanger.command, rbr_in\n+            exchanger.command, rbr_in\n         )\n         df_out = instrument_reader(rbr_out, prefix=\"output ::\").read_pandas()\n         print(fut.result())\ndiff --git a/examples/gcstorage_example.py b/examples/gcstorage_example.py\nindex ef2aeaa9..90c1302a 100644\n--- a/examples/gcstorage_example.py\n+++ b/examples/gcstorage_example.py\n@@ -1,10 +1,10 @@\n import xorq.api as xo\n-from xorq.caching import GCCache\n+from xorq.caching import GCSCache\n \n \n bucket_name = \"expr-cache\"\n con = xo.connect()\n-cache = GCCache.from_kwargs(bucket_name=bucket_name)\n+cache = GCSCache.from_kwargs(bucket_name=bucket_name, source=con)\n \n \n expr = xo.deferred_read_csv(\ndiff --git a/python/xorq/common/utils/gcloud_utils.py b/python/xorq/common/utils/gcloud_utils.py\nindex 5f3f9093..b95b0653 100644\n--- a/python/xorq/common/utils/gcloud_utils.py\n+++ b/python/xorq/common/utils/gcloud_utils.py\n@@ -11,7 +11,7 @@ from attr.validators import (\n from google.cloud import storage\n from toolz import curry\n \n-from xorq.caching.storage import Storage\n+from xorq.caching.storage import CacheStorage as Storage\n from xorq.config import _backend_init\n from xorq.vendor.ibis.backends import BaseBackend"
  },
  "sys-version_info": [
    3,
    13,
    11,
    "final",
    0
  ]
}