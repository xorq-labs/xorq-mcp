{"by": "HPsquared", "id": 43182410, "kids": [43182423], "parent": 43178412, "text": "This is the Waluigi effect.<p>Whereby &quot;after you train an LLM to satisfy a desirable property P, then it&#x27;s easier to elicit the chatbot into satisfying the exact opposite of property P.&quot;<p><a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Waluigi_effect#cite_ref-5\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Waluigi_effect#cite_ref-5</a>", "time": 1740564848, "type": "comment"}