{"by": "hackerzr", "id": 43182471, "parent": 43182470, "text": "Thoughts on this?<p>Pinecone just published a technical deep-dive into how they&#x27;re redesigning their vector database architecture to handle three increasingly common workloads:<p>- Recommender systems requiring 1000s of QPS\n- Semantic search across billions of documents\n- Agentic systems with millions of independent agents operating simultaneously<p>Among other things, a &quot;log structured indexing&quot; approach uses immutable &quot;slabs&quot; to balance freshness and performance. Writes go to in-memory memtables that flush to blob storage as L0 slabs using fast indexing (scalar quantization&#x2F;random projections), while background compaction creates larger slabs with more intensive partition&#x2F;graph-based indexes.<p>This design solves a few issues:\nIt enables high freshness for all workloads (including recommenders)\nIt supports both graph-based and other indexing approaches in the same system\nIt eliminates the traditional build&#x2F;serve split for recommender workloads\nIt provides predictable caching between local SSD and memory<p>They&#x27;re also introducing disk-based metadata filtering using bitmap indices adapted from data warehouses, which helps with high-cardinality filtering use cases like access control lists.<p>What do you think?", "time": 1740565628, "type": "comment"}